> Cory Doctorow has explored the immediate followup of post-singularity economics in Down and Out in the Magic Kingdom and in Walkaway. Are there any other relevant interesting writing (fiction or non-fiction) in describing how alternative economic systems can work for an underclass in a advanced capitalistic economy that is more neofeudal than anything else (where jobs have been automated away and all capital accrues to a small oligarchy). I’m interested in people building alternatives outside that system if it can’t be avoided.

Below are some works that scratch a similar itch to *Down and Out in the Magic Kingdom* and *Walkaway*: worlds sliding into “rentier / platform / neo-feudal” control, with people *actually trying to build* parallel systems (commons, mutual aid, co-ops, post-work cultures) rather than just doing grim resistance.

## Fiction that shows people building outside the fiefdoms

* **Octavia E. Butler — *Parable of the Sower* (and its sequel *Parable of the Talents*)**
  Near-future social collapse where privatization, gated enclaves, and “company town” logic reassert themselves—while the protagonist assembles a traveling, protective micro-society and then founds a community with an explicit “how do we live” ethic. It’s one of the best “underclass builds an alternative while the world turns predatory” novels.

* **Marge Piercy — *Woman on the Edge of Time***
  Alternates between a brutal present (poverty, institutional power) and a vividly sketched future community (Mattapoisett) built around shared provisioning and non-domination—explicitly contrasted with a hyper-capitalist “richies” dystopia. It’s very “another system is imaginable, but it has to be defended/made real.”

* **Kim Stanley Robinson — *New York 2140***
  A flooded NYC where many ordinary people live in co-ops and pooled-resource arrangements, and the plot keeps coming back to collective action against finance capitalism (not just individual survival). If you liked *Walkaway*’s “systems thinking,” Robinson does a lot of that, but through climate + political economy.

* **Ursula K. Le Guin — *The Dispossessed***
  The classic “ambiguous utopia”: an anarchist/anarcho-syndicalist society on Anarres set against a wealthier capitalist world on Urras. It’s less “scrappy maker commune” and more “what are the real failure modes and moral tensions of a moneyless, non-propertarian society?”—but it’s foundational for this whole conversation.

* **Marshall Brain — *Manna: Two Visions of Humanity’s Future***
  Very direct on your “automation wipes out jobs + oligarchy hoards capital” premise: first a grim track (mass unemployment + warehouse-like welfare housing), then a contrasting track (a society with universal basic income / abundance). It’s blunt, but it’s one of the most “post-work underclass” readable thought experiments out there—and it’s available online.

* **Ruthanna Emrys — *A Half-Built Garden***
  First-contact meets “post-capitalist reconstruction”: set after a political upheaval where networked, self-organizing communities become major actors, and the book takes governance and legitimacy seriously (not just vibes). If you want “people building alternatives that are messy, political, and real,” this is a strong fit.

* **Anthology — *Sunvault: Stories of Solarpunk and Eco‑Speculation***
  If what you want is “lots of worked examples” of community-scale alternatives—energy commons, cooperative cultures, mutual-aid futures—solarpunk anthologies are basically a buffet of that. *Sunvault* is often cited as an early broad solarpunk collection.

## Non-fiction that pairs “neo-feudal diagnosis” with “how do we build outside it?”

### 1) Naming the neo-feudal shape (rentism, platform fiefs, enclaves)

* **Peter Frase — *Four Futures: Life After Capitalism***
  One of the cleanest frameworks for your question: futures mapped by *abundance vs scarcity* and *equality vs hierarchy*, producing four outcomes (including “rentism” and “exterminism,” which get very close to “automated neo-feudal enclaves”).

* **Yanis Varoufakis — *Technofeudalism: What Killed Capitalism***
  A big, provocative argument that platform power looks less like classic competitive capitalism and more like digital “fiefdoms” extracting rents. Even if you disagree, it’s very on-target for the “oligarchy + automated labor + everyone else locked into someone’s infrastructure” vibe.
  Worth noting: the “technofeudalism” framing is debated—some critics argue it obscures the way these systems still run on very capitalist dynamics and labor exploitation.

### 2) “Building outside” toolkits (co-ops, commons, parallel institutions)

* **Trebor Scholz & Nathan Schneider (eds.) — *Ours to Hack and to Own: The Rise of Platform Cooperativism***
  Directly about building *owned-and-governed-by-users/workers* alternatives to platform monopolies—exactly the “build outside the system (but still inside the network)” problem.

* **Michel Bauwens & Vasilis Kostakis — writing on “open cooperativism”**
  If you’re interested in “commons-based” production (open-source / shared knowledge) *combined with* cooperative ownership and livelihoods, open cooperativism is a useful design pattern: cooperatives that feed and steward shared commons rather than enclosing them.

* **Maliha Safri, James D. B. Fleetwood, & Stephen Healy — *Solidarity Cities: Confronting Racial Capitalism, Mapping a Just Economy***
  Looks at city-scale ecosystems of co-ops, mutual-aid style provisioning, community finance, and other solidarity-economy institutions—useful if you want grounded “what does the alternative actually look like on the ground?” material.

* **Emily Thaden & Greg Rosenberg (eds.) — *The Community Land Trust Reader***
  Not “post-singularity,” but very relevant to “underclass builds a survivable outside”: land/housing de-commodified through trust structures is one of the most practical ways communities reduce exposure to rentier extraction.

### 3) “Post-work but not neo-feudal” visions (how abundance *could* cash out)

* **Paul Mason — *PostCapitalism: A Guide to Our Future***
  Argues the digital revolution can undermine market/ownership logics, and points to things like parallel currencies, co-ops, and self-managed online spaces as seeds of a postcapitalist transition.

* **Aaron Bastani — *Fully Automated Luxury Communism***
  A maximalist “abundance + automation can support a post-scarcity politics” manifesto. Whether or not you buy it, it’s explicitly grappling with “what should an automated economy do for everyone, not just owners?”

## If you want a “starter path” that’s close to *Walkaway*’s vibe

1. **Fiction:** *Parable of the Sower* → *New York 2140* → *The Dispossessed*
2. **Nonfiction:** *Four Futures* (frame the neofeudal outcome) → *Ours to Hack and to Own* (platform-level counterbuilds) → *Community Land Trust Reader* (physical-world decommodification)

If you tell me which *part* of “building outside” you want emphasized—digital commons/platform escape, housing/land, food/energy commons, or governance models—I can narrow this to a tighter list (and suggest a couple more in that exact lane).

> Let’s take it back from speculative fiction and into speculative reality as we see the slow AI takeoff happening now. Let’s do an analysis and critique of some contemporary thinking…  Let’s do into a deep dive into some of the post singularity economics talk that’s been popular on twitter circles lately… “To restate the argument in more obvious terms.
> The eventual end state of labor under automation has been understood by smart men (ie not shallow libshits) for ≈160 years since Darwin Among the Machines. The timeline to full automation was unclear. Technocrats and some Marxists expected it in the 20th century.
> The last 14 years in AI (since connectionism won the hardware lottery as evidenced by AlexNet) match models that predict post-labor economy by 2035-2045. Vinge, Legg, Kurzweil, Moravec and others were unclear on details but it's obvious that if you showed them the present snapshot in say 1999, they'd have said «wow, yep, this is the endgame, almost all HARD puzzle pieces are placed».
> The current technological stack is almost certainly not the final one. That doesn't matter. It will clearly suffice to build everything needed for a rapid transition to the next one – data, software, hardware, and it looks extremely dubious that the final human-made stack will be paradigmatically much more complex than what we've done in these 14 years.
> Post-labor economy = post-consumer market = permanent underclass for virtually everyone and state-oligarchic power centralization by default. 
> As an aside: «AI takeover» as an alternative scenario is cope for nihilists and red herring for autistic quokkas. Optimizing for compliance will be easier and ultimately more incentivized than optimizing for novel cognitive work.  There will be a decidedly simian ruling class, though it may choose to *become* something else. But that's not our business anon. We won't have much business at all.  
> The serious business will be about the technocapital deepening and gradually expanding beyond Earth.
> Frantic attempts to «escape the permanent underclass» in this community are not so much about getting rich as about converting wealth into some equity, a permanent stake in the ballooning posthuman economy, large enough that you'd at least be treading water on dividends, in the best case – large enough that it can sustain a thin, disciplined bloodline in perpetuity.
> Current datacenter buildup effects and PC hardware prices are suggestive of where it's going. Consumers are getting priced out of everything valuable for industrial production, starting from the top (microchips) and the bottom (raw inputs like copper and electricity). The two shockwaves will be traveling closer to the middle. This is not so much a "supercycle" as a secular trend. 
> American resource frenzy and disregard for diplomacy can be interpreted as a state-level reaction to this understanding.
> There certainly are other factors, hedges for longer timelines, institutional inertia and disagreement between actors that prevents truly desperate focus on the new paradigm. But the smart people near the levers of power in the US do think in these terms.
> Speaking purely of the political instinct, I think the quality of US elite is very high, and they're ahead of the curve, thus there are even different American cliques who have coherent positions on the issue. Other global elites, including the Chinese one, are slower on the uptake. But this state of affairs isn't as permanent as the underclass will be. 
> 
> For people who are not BOTH extremely smart and agentic – myself included – I don't have a solution that doesn't sound hopelessly romantic and naive.” And “you have three minutes to escape the perpetual underclass
> Jan 17, 2026
> I had a dream last night I went to work at Amazon. Joining the Bezos neofeudal empire. This post is directed at anyone with talent who works at a tech company ushering in this future.
> 
> 
> Have you thought about how this is going to play out? I understand you may be at a place where you are insecure about money, and that insecurity is what drives you. But why do you think having more money will fix that insecurity?
> In the future, when labor is fully marginalized and capital is the only force, you will not be able to afford GPT$$$ (it’s $1B per month), only the billionaires will. GPT$$$ is surely smart enough to separate you from whatever you have, be that with targeting advertising, a scam you fall for, or lobbying your government to take it from you.
> A pile of money will buy you nothing in the neofeudal world.
> 
> 
> Historically, there has been some loyalty to the subjects of a feudal empire because labor had some value. You needed the peasants to grow the grain so you could tax it and take it and have leverage over others by having grain to offer them. When the grain is produced by machines, the peasants are cut out of the loop.
> The solution to this is not to accumulate grain, buy shares in a granary, or anything else like that. They will find a way to make whatever you have worthless. Because the feudal world didn’t operate on capitalist principles, and neither will the neofeudal world.
> 
> 
> If you work at a large company, if you work according to the principles of modern capitalism, where all the fish will be eaten by the bigger fish, and all will be eaten by the sharks, and all the sharks will be eaten by bigger sharks, you are actively bringing about the system that will kill you.
> Have you considered not participating? If you participate, we all lose. We will either all be in the underclass together or not.”

Below is a “deep-dive critique” of the two arguments you pasted, but written in a way that strips out the status‑posturing, insults, and deterministic vibes and focuses on the actual claims.

I’m going to treat them as two related theses:

* **Thesis A (X thread):** rapid-ish AI progress → full automation by ~2035–2045 → “post‑labor” → “post‑consumer market” → default outcome is oligarchic/state power centralization and a permanent underclass; individual “escape” is basically converting wealth into durable stakes in the machine economy.
* **Thesis B (Hotz post):** in a “neofeudal” regime, money won’t buy safety; if you work inside large tech firms you’re helping build your own cage; the only viable move is to stop participating. ([Geohot][1])

## 1) What’s solid in Thesis A and Thesis B

### Compute + energy really are becoming “first-class” political economy variables

The threads are directionally right that **AI capabilities are getting tied to industrial-scale compute** and that **electricity constraints are increasingly binding**.

* The IEA projects electricity generation to supply data centres growing from **~460 TWh (2024) → >1,000 TWh (2030) → ~1,300 TWh (2035)** in its Base Case, explicitly framing AI-driven data centre demand as a major driver. ([IEA][2])
* Reuters (Jan 2026) reports the U.S. EIA forecasting **record power demand** in 2026–2027, with demand “surging in part due to data centers dedicated to AI and cryptocurrency.” ([Reuters][3])
* Reuters (Jan 2026) also reports PJM (a huge U.S. grid operator) proposing special frameworks for large new loads as data-center demand queues balloon. ([Reuters][4])
* On the corporate side, Reuters describes Meta planning “tens of gigawatts this decade, and hundreds of gigawatts or more over time” under a “Meta Compute” push. ([Reuters][5])
* And Reuters reports OpenAI signing a **$10B+** compute deal with Cerebras, including **up to 750 MW** over three years for inference. ([Reuters][6])

That cluster of facts supports a narrower, defensible claim:

> **Whatever happens to “jobs,” AI is already pushing toward infrastructure concentration** (chips, power, data centres, long‑term power contracts), which creates real oligopoly and rent‑extraction risk.

### “Frontier training is expensive” is empirically supported (even if people meme the numbers)

Hotz says “GPT$$$ is $1B per month.” ([Geohot][1])
Taken literally, that’s almost certainly hyperbole. But the *shape* of the claim—frontier AI is expensive enough to concentrate ownership—has support:

* Epoch AI estimates training costs for frontier models have been growing ~**2–3× per year** for years and suggests **largest training runs could exceed $1B by 2027**, making them “too expensive for all but the most well-funded organizations.” ([Epoch AI][7])
* Epoch AI also estimates OpenAI’s 2024 compute spend was in the **billions**, with substantial inference spend alongside R&D/training. ([Epoch AI][8])
* Reuters Breakingviews (Oct 2025) frames the core business reality: training and inference impose ongoing, heavy “direct costs” unlike classic software, and reports a claim that OpenAI expects to burn through **$115B by end of 2029** (per that commentary’s sourcing). ([Reuters][9])

So: **the “compute aristocracy” risk is not fantasy**—it’s one of the most grounded parts of the whole discourse.

## 2) Where the “post‑labor ⇒ post‑consumer ⇒ permanent underclass” chain breaks

The X‑thread logic is a *chain*. It only needs one weak link to fail. There are at least three.

### Weak link #1: “post‑labor” is not the same thing as “no one has income”

Even mainstream institutions that warn about disruption usually frame it as “affecting” jobs via replacement *and* complementarity—not “end of labor in 20 years.”

* The IMF’s public framing (Jan 2024) is that AI will affect ~**40% of jobs globally**, replacing some, complementing others, with policy choices determining whether inequality worsens. ([IMF][10])

That doesn’t refute “post‑labor,” but it flags that **there is no consensus** that (a) near‑term displacement dominates (b) to the point of near‑universal redundancy.

More importantly: even if we grant **extreme automation**, “income” can be politically and institutionally defined (wages, transfers, dividends, public services). Which leads to…

### Weak link #2: “post‑consumer market” is not a stable endpoint if the system still wants profits

Here’s the macro constraint the thread hand-waves:

* A capitalist investment cycle needs **effective demand**. If most people can’t buy things, *a lot of capital’s profit-making outlets shrink* (unless the economy becomes primarily “selling to the state,” or “selling luxuries to a tiny elite,” or “selling capital goods to itself,” etc.).

So if you posit “almost everyone is permanently income‑starved,” you’ve implicitly posited one of these transitions:

1. **The system redistributes enough to keep mass demand alive** (UBI, universal basic services, wage subsidies, etc.)
2. **The system shifts away from consumer profit dependence** (state procurement / militarized techno-state / command allocation)
3. **The system accepts stagnation + repression** (a smaller consumer economy + policing the excluded)

The X thread jumps from “automation is possible” to “(3) is default.” That’s not *impossible*, but it’s not a *default* in any “economic equilibrium” sense. It’s a **political choice** (or political failure).

### Weak link #3: It treats politics as epiphenomenal, except when it wants elites to be clairvoyant

A lot of “AI neofeudalism” talk does this move:

* *Politics doesn’t matter* (doom is inevitable; participation is pointless)…
* …except *politics matters a lot* when explaining why elites are allegedly “ahead of the curve,” coordinating resource policy, shaping diplomacy, etc.

Those can’t both be true at the same time, at least not without a more explicit theory of the state, legitimacy, and coordination.

If elites are competent enough to steer grand strategy, they’re also competent enough to recognize that **a huge immiserated majority is a security problem**—and then you’re back to “redistribution/repression/exit” tradeoffs, not a single deterministic path.

## 3) Internal contradictions that are worth calling out

### Contradiction A: “Escape requires equity” vs “they’ll make whatever you have worthless”

One post says the “smart move” is to convert wealth into durable stakes in the expanding machine economy (equity/dividends/bloodline stake). The other says *money and ownership claims will be nullified* in neofeudalism. ([Geohot][1])

Those are incompatible without further assumptions.

* If property rights remain legible enough for “equity stakes” to matter, then yes, ownership is power—*but that also implies the underclass can politically contest ownership regimes* (taxes, antitrust, regulation, public ownership, labor rights, etc.).
* If property rights become arbitrary and “they will make whatever you have worthless,” then “escape via equity” is fantasy. Your stake is only as durable as the regime.

This matters because the **real** strategic question is: *what institutions make claims enforceable* (law, violence, legitimacy, collective action), not “should I buy shares.”

### Contradiction B: “AI takeover is a red herring” vs “AI is powerful enough to strip everyone’s wealth”

Hotz’s post imagines a super‑capable GPT that can reliably separate non‑elites from their wealth through scams/ads/lobbying. ([Geohot][1])
The X thread dismisses “AI takeover” as a cope/red herring and emphasizes compliance optimization.

You can reconcile these, but you have to say explicitly:

* AI is powerful as a *persuasion/optimization* engine inside existing institutions,
* but not autonomous in a way that supersedes elites.

That’s a coherent model. But then the “ruling class” story is not about AI at all—it’s about **institutional control of persuasion, surveillance, and allocation**. Which again is politics, not inevitability.

## 4) A more grounded critique of Hotz’s “stop participating” stance

Hotz’s Jan 17 post is basically an “exit” moral argument: don’t work for the neofeudal machine. ([Geohot][1])
His Jan 18 follow-up is more operational: build/open-source systems that reduce lock‑in; “who has root?”; commoditize compute; spread ownership of “robots.” ([Geohot][11])

Those two together contain something important, but also a trap.

### The important part: “ownership of the means of automation” is the crux

When Hotz says “who owns the robots… who has root?” he’s pointing at a core political-economic lever: **control of productive capital**. ([Geohot][11])

That maps cleanly onto your original interest: alternatives for an underclass in a neofeudal-ish advanced economy.

* If compute + robots are scarce and privately controlled, you get rent extraction.
* If compute + robots become commodities / commons / broadly ownable, you get a fighting chance at autonomy.

### The trap: individual non-participation is not a scalable strategy by itself

“Have you considered not participating?” sounds clean, but it’s under-specified in a world of coordination problems:

* If only a few people exit, you mainly change *your* exposure, not the system.
* If enough people exit, you need institutions that absorb them (co-ops, open tech ecosystems, alternative financing, community procurement, etc.)—otherwise it’s just self-sacrifice.

Hotz’s Jan 18 post implicitly acknowledges this by describing **institution-building** (open-source, profitable product companies, alternative compute stacks). ([Geohot][11])
That’s the more “real” move than the sermon.

## 5) The missing middle: what “slow takeoff” economics actually tends to look like

If we assume *continued rapid AI progress* but *diffusion with friction* (regulation, integration costs, liability, energy constraints), the near-term political economy often looks like:

1. **Task-level automation, not job-level disappearance.**
   A lot of roles get re-bundled; some shrink; some expand; new “human glue” work emerges.

2. **Rents concentrate where bottlenecks concentrate.**
   Right now, bottlenecks look like: frontier compute, proprietary data, distribution platforms, regulatory capture, energy access. The IEA/Reuters reporting on power and the scale of Big Tech buildouts is consistent with that. ([IEA][2])

3. **Inequality becomes about asset ownership more than wages.**
   There’s serious contemporary work modeling how AI can shift distribution depending on who owns capital and which tasks are automated. ([IMF][12])

This “missing middle” matters because it suggests your core question (“how do alternatives work for the underclass?”) is less about a single apocalypse moment and more about **fighting enclosure during diffusion**.

## 6) If the goal is “building alternatives outside the system,” what actually composes an alternative?

In a slow‑takeoff world, you don’t need (or get) a total exit. You need **parallel institutions** that do three things:

### A) Secure subsistence outside rent chokepoints

Underclass vulnerability is usually: housing, health, energy, food. If those are fully rentized, “freedom” is performative.

Concrete institution patterns (non-fiction, real-world):

* **Community land trusts / limited-equity housing co-ops** (de-rent housing)
* **Energy co-ops / community solar + storage** (de-rent power)
* **Mutual aid + union benefit funds** (de-risk shocks)

These aren’t “post-singularity,” but they’re exactly how you keep a bottom layer from being fully captive when bargaining power drops.

### B) Own or govern the automation stack (compute, models, robots)

This is the “who has root?” axis Hotz highlights. ([Geohot][11])
If compute is the new land, you need versions of:

* **Open tooling** (software you can fork, inspect, self-host)
* **Commodity hardware pathways** (so you’re not permanently paying rent to a GPU landlord)
* **Collective procurement** (co-ops that buy/operate compute for members)

You don’t have to believe in “full post-labor by 2040” to see why this matters: the IEA and Reuters reporting already shows energy/compute scaling is becoming a strategic arena. ([IEA][2])

### C) Build collective leverage, not just personal purity

The X thread’s fatalism and Hotz’s moralizing both underplay this: **the underclass only “exists” politically when atomized.**

The most important “alternative economy” is often not a separate currency or commune; it’s **institutions that let people negotiate as a block**:

* unions (including new forms for contractors/creators)
* professional associations that set norms and push interoperability
* municipal/state procurement policies that buy open systems (creating non-rent markets)

If you want one sentence summary of the critique:

> The doom threads treat the future as a technology outcome; the actionable reality is that it’s an ownership + governance outcome.

## 7) A short list of “tell me what world we’re in” indicators

If you want to stay grounded over the next 2–5 years, watch indicators that discriminate between “rentized neofeudalism” vs “broad prosperity with automation”:

1. **Compute pricing power:** do inference/training costs fall in a way that broadens access, or do they remain rentized behind a few gatekeepers? (Epoch’s work and Reuters’ reporting are useful here.) ([Epoch AI][8])
2. **Energy politics:** do grids and regulators effectively socialize/coordinate expansion, or do data centers bid power away from households/small industry? (PJM/EIA coverage is a signal.) ([Reuters][4])
3. **Interoperability + antitrust:** do we get “right of exit” dynamics (Doctorow’s frame) or deeper lock-in? (This is where “enshittification” analysis becomes economically relevant.) ([WIRED][13])
4. **Distribution mechanisms:** are governments experimenting with dividends/social wealth funds/UBS, or mainly policing and austerity? (Direction matters more than rhetoric.)

## 8) A few non-fiction anchors that match your “build alternatives” interest

If you want reading that’s closer to “speculative reality” than SF, and directly relevant to “neofeudal / rent” dynamics + alternatives:

* **Yanis Varoufakis, *Technofeudalism*** (modern “feudal” analogy applied to platforms / cloud capital). ([PenguinRandomhouse.com][14])
* **Acemoglu & Restrepo on tasks/automation** (why “automation” doesn’t map cleanly to “no jobs,” and what actually drives labor demand). ([American Economic Association][15])
* **IMF / OECD work on AI and inequality/adoption divides** (useful for staying empirical as discourse gets messier). ([IMF][12])
* **Social wealth fund / universal dividend proposals** (a concrete “broad ownership of capital” alternative to pure wage dependence). ([People's Policy Project][16])

---

If you want to go one layer deeper, I can take your pasted X-thread claims and “formalize” them into a minimal model (what must be true for each step to hold), then stress-test it with counterexamples (historical + current AI economics). But the core critique won’t change: **the threads are strongest on compute/energy concentration, and weakest on the inevitability of a permanent underclass absent explicit political choices.**

[1]: https://geohot.github.io/blog/jekyll/update/2026/01/17/three-minutes.html "https://geohot.github.io/blog/jekyll/update/2026/01/17/three-minutes.html"
[2]: https://www.iea.org/reports/energy-and-ai/energy-supply-for-ai "https://www.iea.org/reports/energy-and-ai/energy-supply-for-ai"
[3]: https://www.reuters.com/business/energy/us-power-use-beat-record-highs-2026-2027-eia-says-2026-01-13/ "https://www.reuters.com/business/energy/us-power-use-beat-record-highs-2026-2027-eia-says-2026-01-13/"
[4]: https://www.reuters.com/legal/litigation/pjm-unveils-plan-tackle-ai-driven-power-demand-surge-2026-01-16/ "https://www.reuters.com/legal/litigation/pjm-unveils-plan-tackle-ai-driven-power-demand-surge-2026-01-16/"
[5]: https://www.reuters.com/technology/meta-build-gigawatt-scale-computing-capacity-under-meta-compute-effort-2026-01-12/ "https://www.reuters.com/technology/meta-build-gigawatt-scale-computing-capacity-under-meta-compute-effort-2026-01-12/"
[6]: https://www.reuters.com/technology/openai-buy-compute-capacity-startup-cerebras-around-10-billion-wsj-reports-2026-01-14/ "https://www.reuters.com/technology/openai-buy-compute-capacity-startup-cerebras-around-10-billion-wsj-reports-2026-01-14/"
[7]: https://epoch.ai/blog/how-much-does-it-cost-to-train-frontier-ai-models "https://epoch.ai/blog/how-much-does-it-cost-to-train-frontier-ai-models"
[8]: https://epoch.ai/data-insights/openai-compute-spend "https://epoch.ai/data-insights/openai-compute-spend"
[9]: https://www.reuters.com/commentary/breakingviews/how-infer-method-to-openais-madness-2025-10-15/ "https://www.reuters.com/commentary/breakingviews/how-infer-method-to-openais-madness-2025-10-15/"
[10]: https://www.imf.org/en/blogs/articles/2024/01/14/ai-will-transform-the-global-economy-lets-make-sure-it-benefits-humanity "https://www.imf.org/en/blogs/articles/2024/01/14/ai-will-transform-the-global-economy-lets-make-sure-it-benefits-humanity"
[11]: https://geohot.github.io/blog/jekyll/update/2026/01/18/how-do-i-stop.html "https://geohot.github.io/blog/jekyll/update/2026/01/18/how-do-i-stop.html"
[12]: https://www.imf.org/en/publications/wp/issues/2025/04/04/ai-adoption-and-inequality-565729 "https://www.imf.org/en/publications/wp/issues/2025/04/04/ai-adoption-and-inequality-565729"
[13]: https://www.wired.com/story/tiktok-platforms-cory-doctorow "https://www.wired.com/story/tiktok-platforms-cory-doctorow"
[14]: https://www.penguinrandomhouse.com/books/751443/technofeudalism-by-yanis-varoufakis/ "https://www.penguinrandomhouse.com/books/751443/technofeudalism-by-yanis-varoufakis/"
[15]: https://www.aeaweb.org/articles?id=10.1257%2Fjep.33.2.3 "https://www.aeaweb.org/articles?id=10.1257%2Fjep.33.2.3"
[16]: https://www.peoplespolicyproject.org/projects/social-wealth-fund/ "https://www.peoplespolicyproject.org/projects/social-wealth-fund/"
> Let’s do some more spitballing first. A few other things to consider - besides optionality (which anyone playing power games wants) and social approval (ultimately what most people in power need) there is also the consideration that there are more players on the chess board that won’t collude including another peer state superpower (China) and other strong players. I actually live in Japan now. I’m training the most advanced LLMs in Japan with a tiny team based off of open source technologies. Our Japanese language capabilities match frontier labs, it costs us thousands of dollars to adapt open source models that are no more than 6mo behinds frontier (all can do close to 100% on AIME, can do agentic coding). In a multipolar world w infinite n-1 actors does it really matter in slow take off (hard limited by power, manufacturing, competition) ? I don’t see Japanese society making decisions similar to what the US seems to be rolling over on in terms of fascism, nor European nations or most liberal democracies.

Yeah—what you’re describing (small team + open weights + “only months behind frontier” + adaptation costs in the *thousands*, not the *millions*) is a very big deal, and it pushes hard against the “one simian ruling class owns GPT$$$ and everyone else is a permanent peasant” story.

But it doesn’t completely kill the “neofeudal” risk. It mostly *moves the choke points*.

Here’s how I’d spitball it.

## 1) “Infinite n‑1 actors” changes the AI story… but only for the parts that are actually copyable

There are two different things people sloppily bundle into “AI power”:

### A. Model capability (weights + training recipes)

This is the part where your experience matters most.

You can already see it in public evals: in AIME-Preview’s AIME 2025 table, a top proprietary model in that set (o3‑mini‑high) is ~80.85, while an open model (DeepSeek‑R1) is ~70.00—i.e., *behind but not galaxy-behind*, and plenty for a huge range of real work. 

So the “LLMs are so expensive only the aristocracy can think” framing is directionally wrong **for the median useful capability**. If the underclass can run “good enough” cognition, you don’t get an *information monopoly* the way doom threads imply.

### B. Industrial-scale deployment (compute, power, data centers, supply chains)

This is where the “neofeudal” feel can still arrive, even if weights are abundant.

Because the controlling resource isn’t “who has the smartest text predictor,” it’s increasingly:

* **who has cheap, reliable power**
* **who has GPU allocations**
* **who gets grid interconnect priority**
* **who gets to build (permitting, water, land, disaster resilience)**
* **who has long-term contracts and the balance sheet to survive price spikes**

And that stuff *does* re-centralize.

Japan is a great example: Reuters reported a plan for a massive data-centre hub in Toyama that would eventually reach **3.1 GW**—that’s “grid-scale” as a single campus. ([Reuters][1])
Wood Mackenzie similarly projects Japan’s data centres could consume electricity comparable to **15–18 million households by 2034**, and frames the boom as driving a big share of demand growth. ([Wood Mackenzie][2])
UTokyo + Fujitsu even announced a trial for **inter-regional workload shifting** explicitly motivated by data-centre power demand, which is basically an admission that power constraints are now a first-order systems issue. ([Fujitsu][3])

So: *yes*, lots of n‑1 actors can have strong models. But the world can still be “feudal” around **energy + infrastructure access**.

## 2) Multipolarity doesn’t eliminate concentration; it makes it “many fiefs” instead of one empire

If you buy the “slow takeoff is hard-limited by power/manufacturing,” that implies scarcity at the infrastructure layer. Scarcity tends to produce rent-seeking. Even if actors don’t collude, you can get a similar social shape via:

* **parallel concentration** (each bloc centralizes inside itself)
* **national-security framing** (“compute is strategic” → licensing, monitoring, procurement gatekeeping)
* **platform distribution choke points** (even if models are open, the underclass lives inside a few app/payment/identity stacks)

So the multipolar version of doom is less “one global oligarchy,” more:

> “A handful of state–corporate coalitions each run their own compute–energy complex, and ordinary people get ‘access’ mostly as tenants.”

That’s still ugly, but it’s *politically* much more contestable (because there are alternative jurisdictions, alternative suppliers, and defections).

## 3) Your “Japan won’t do US-style authoritarian stuff” instinct is plausible—but not something you can treat as guaranteed

It’s totally reasonable to expect divergence between democracies and an increasingly illiberal US trajectory, and there’s some empirical support for *current* divergence.

* Freedom House rates **Japan “Free” at 96/100** in 2025. ([Freedom House][4])
* Civicus rates Japan’s civic space **“Open” (88/100)**, and the time series shows Japan sitting in the “Open” band recently. ([Civicus Monitor][5])
* Civicus rates the **United States “Obstructed” (56/100)** and says it downgraded the US after a sharp deterioration in freedoms. ([Civicus Monitor][6])

Europe also isn’t “rolling over” in the simplistic way doom-Twitter claims. The EU AI Act *explicitly bans* some categories of use and brings high-risk systems into scope on a staged timeline; the Commission has publicly rejected calls to “pause” the rollout. ([AI Act Service Desk][7])

So the “liberal democracies will all converge to one fascist compute-caste regime” claim is not obviously supported by present governance trajectories.

But there’s a big caveat:

### Security pressure is the classic way democracies slide

Even Japan’s “Open” civic-space page includes recent updates that mention concerns around **anti-spy law proposals** and protest policing. ([Civicus Monitor][5])

That doesn’t mean Japan is “becoming the US.” It means: if you’re thinking in 10–20 year horizons, your base case should include “liberal norms get stress-tested under geopolitics + misinformation + surveillance tech.”

Multipolarity can *increase* that pressure (arms-race dynamics), even while it *decreases* the plausibility of a single global colluding oligarchy.

## 4) The key reframing: open models reduce *cognitive scarcity*; they don’t automatically prevent *rent scarcity*

If your cheap adaptation story keeps holding, then the underclass problem is less “you can’t afford intelligence” and more:

* you can afford intelligence, **but you can’t afford housing**
* you can afford intelligence, **but you can’t afford energy**
* you can afford intelligence, **but you’re locked out of ownership**
* you can afford intelligence, **but your entire life runs on paywalled platforms**

In other words: the “neofeudal” problem becomes *classic political economy* again: asset ownership, land, energy, and monopoly infrastructure—now with AI turbocharging the winners.

That’s why a small team in Japan can be near-frontier at language tasks and yet still be living inside a world where compute/power is turning into a quasi-strategic resource.

## 5) So… does it “really matter” that it’s multipolar with many actors?

It matters a lot, but in specific ways:

### What multipolarity + open source *does* buy you

* **Exit options for states and talent.** If one country goes hard illiberal, others can credibly say “come here,” and that disciplines policy (at least somewhat).
* **No single chokehold on cognition.** “One model to rule them all” is less plausible when weights, distillation, and fine-tuning diffuse quickly.
* **Competitive pressure against price gouging.** Even a small gap (70 vs 80 on AIME-like evals) can be enough to keep many markets contestable. 

### What it *doesn’t* automatically solve

* **Infrastructure scarcity**: power, grid connections, GPU supply, data-centre real estate. Japan’s big buildout signals that this is already the battleground. ([Reuters][1])
* **Distribution lock-in**: app stores, identity/payment rails, cloud procurement, corporate standards.
* **Domestic inequality**: you can be a “Free” democracy and still run a brutal rentier housing regime.

## 6) If I were you (tiny open-source LLM team in Japan), the “anti-neofeudal” lever I’d obsess over isn’t model IQ

It’s “how do we prevent compute/power becoming landlordism?”

A few spitball targets that fit your situation:

1. **Make “good enough” models locally runnable and boringly reliable**
   The more workloads that can run on modest clusters (or on-prem), the less leverage hyperscalers have.

2. **Standardize portability** (weights formats, inference stacks, eval harnesses, deployment recipes)
   Doctorow’s “right of exit” idea but applied to AI deployments: reduce switching costs so nobody can trap users behind a single stack.

3. **Treat Japanese government procurement as a wedge**
   Japan’s Digital Agency has detailed procurement/utilization guidance for generative AI in government, including governance roles like CAIO and risk processes, and it explicitly frames government leading adoption while managing risks. ([デジタル庁][8])
   Procurement is a powerful way to create a “market for non-rent extraction” (open standards, interoperability requirements, auditability requirements).

4. **Energy-aware AI as competitive advantage**
   In a power-constrained world, “better tokens-per-joule” isn’t optimization nerdism; it’s sovereignty.

5. **Assume geopolitics will occasionally break your dependencies**
   Not because of “collusion,” but because of export controls, diplomatic spats, or grid rationing. Multipolarity increases this kind of volatility.

---

Net: your lived experience is a strong counterexample to “AI cognition will be permanently monopolized.” The harder question is whether *infrastructure* becomes monopolized in ways that turn most people into tenants anyway.

If you want, we can keep spitballing but make it sharper by picking one axis:

* **Japan-specific political economy** (what levers actually exist in Japanese institutions / procurement / industrial policy)
* **Multipolar AI blocs** (how export controls + alliances affect open source diffusion)
* **Underclass prevention mechanics** (what stops “rentier underclass” even when cognition is cheap)

[1]: https://www.reuters.com/business/media-telecom/japans-biggest-data-centre-hub-planned-toyama-prefecture-document-2025-12-19/?utm_source=chatgpt.com "Japan's biggest data centre hub planned in Toyama prefecture - document"
[2]: https://www.woodmac.com/press-releases/japan-data-centers-power-demand/?utm_source=chatgpt.com "Japan data centers power demand"
[3]: https://global.fujitsu/en-global/pr/news/2025/12/24-01?utm_source=chatgpt.com "The University of Tokyo and Fujitsu launch trial for Japan's ..."
[4]: https://freedomhouse.org/country/japan/freedom-world/2025?utm_source=chatgpt.com "Japan: Freedom in the World 2025 Country Report"
[5]: https://monitor.civicus.org/country/japan/ "
      Japan - Civicus Monitor
    "
[6]: https://monitor.civicus.org/country/united-states-america/?utm_source=chatgpt.com "United States of America"
[7]: https://ai-act-service-desk.ec.europa.eu/en/ai-act/timeline/timeline-implementation-eu-ai-act?utm_source=chatgpt.com "Timeline for the Implementation of the EU AI Act"
[8]: https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/6e45a64f/20250527_resources_standard_guidelines_guideline_04.pdf "ガイドラインの英語版（仮訳）Provisional Translation of “The Guideline for Japanese Governments’ Procurements and Utilizations of Generative AI for the sake of Evolution and Innovation of Public Administration”.pdf"

