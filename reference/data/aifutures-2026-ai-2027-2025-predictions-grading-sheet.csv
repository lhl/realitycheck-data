,,,,,,,,,,
Prediction,Time period,Pace of progress,Explanation,Resolution explanation,Prediction source,"Time at which AI 2027 predicted the resolution value to be achieved (when filled in, this is used for the pace of progress calculation rather than the final 3 columns)",Time when resolution value was achieved in reality,Resolution value,Predicted value,Apr 2025 value
Benchmark: OSWorld,Mid 2025,0.84,We forecasted a rise from 38% to 65%. At end of Aug 2025 the actual SOTA was 61%. Graded by assuming logistic progression.,"https://os-world.github.io
This is for OSWorld-Verified, for which we have more data than OSWorld. OSWorld-Verified, according to OSWorld authors, is apparently approximately the same difficulty level but with some issues fixed.",Footnoote 9,,2025.67,0.608,0.65,0.381
Benchmark: SWEBench-Verified,Mid 2025,0.18,We forecasted a rise from 72% to 85%. At end of Aug 2025 the actual SOTA was 74.5%. Graded by assuming logistic progression.,"72% baseline: https://x.com/polynoamial/status/1870172996650053653
74.5% by Aug 2025: https://www.anthropic.com/news/claude-opus-4-1",Footnote 10,,2025.67,0.745,0.85,0.717
"Coding time horizon, model trajectory",Late 2025,1.04,"The current best 80% time horizon is GPT-5.2 at 55 minutes (version 1.1; there is no measurement for version 1.0). The methodology change from TH1.0 to TH1.1 drops the best model as of AI 2027 publication (Claude 3.7 Sonnet) by 2/3 from 15 to 10 minutes. Because we care more about the pace of progress rather than the absolute values, we look at when the AI 2027 trajectory reaches 55*(3/2)=83 minutes.

In a central AI-2027-speed trajectory from our AI 2027 timelines model, 83 minutes is achieved in Dec 2025.",https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/,"Timelines forecast generated the prediction, see on graph here",2025.98,2025.95,55,51,10
"Coding time horizon, erroneous graph trajectory",Late 2025,0.66,"In our erroneous graph that we published alongside AI 2027, the curve depicting AI 2027's trajectory achieved an 80% time horizon of 83 minutes in Sep 2025.",https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/,Time horizon graph shared at the time of AI 2027 publication,2025.71,2025.95,55,161,10
AI software R&D uplift: OpenBrain,Late 2025,-0.10,"aifuturesmodel.com estimates that AI software R&D uplift was 1.12x as of end of 2025, slightly lower than the 1.13 we estimated in AI 2027 for OpenBrain internally at the end of Apr 2025. It's unclear to what extent the AI Futures Model is predicting internal vs. public capabilities; since AI 2027 publication we've updated toward the gap being smaller.",Estimate based on aifuturesmodel.com,Side panel: capabilities graph at the top,,2026,1.12,1.3,1.13
AI software R&D uplift: Public model,Late 2025,0.44,"aifuturesmodel.com estimates that AI software R&D uplift was 1.12x as of end of 2025. In AI 2027, we depicted 1.12x as being achieved by the best public model in Jul 2025 (based on interpolating between our mid-2025 and late-2025 side panel predictions). It's unclear to what extent the AI Futures Model is predicting internal vs. public capabilities; since AI 2027 publication we've updated toward the gap being smaller.",Estimate based on aifuturesmodel.com,Side panel: capabilities graph at the top,2025.58,2026,1.12,1.2,1.08
Economic value: OpenBrain annualized revenue,Late 2025,1.16,"The highest AGI company annualized revenue is OpenAI at $20B, as of the end of 2025, up from $8.6B when we published AI 2027. In AI 2027, $20B was achieved in Feb 2026 (based on interpolating between our late 2025 and mid 2026 side panel predictions).",https://epoch.ai/data/ai-companies,Side panel,2026.12,2026,20000000000,18000000000,8600000000
Economic value: OpenBrain valuation,Late 2025,0.44,"The highest AGI company valuation is OpenAI at $500B, as of Oct 2 2025, up from $300B when we published AI 2027. In AI 2027, $500B was achieved in Jun 2025 (based on interpolating between our early 2025 and mid 2025 side panel predictions).","Apr 2025: https://techcrunch.com/2025/03/31/openai-raises-40b-at-300b-post-money-valuation/
Oct 2025: https://www.visualcapitalist.com/cp/openai-500b-valuation/",Side panel,2025.5,2025.82,500000000000,900000000000,300000000000
Compute: Agent-1 training FLOP,Late 2025,0.02,"It's difficult to resolve this, but our best guess is that the training run for the leading AI company's best model as of end of 2025 is about the same as the largest training run done by Apr 2025, GPT-4.5 (both are ~4e26 FLOP).","It's hard to resolve this. We have no idea how much compute Opus 4.5 or GPT 5.2 used.  One way to estimate would be to use Epoch's GPT-5 estimate, scaled naively to 5.2 based on their API cost ratio. And using the fact that we think GPT-5.2 is a fresh pre-train (https://www.lesswrong.com/posts/gJyGQrGrojNnCQZgD/aaron_scher-s-shortform#xPZ6Jxgd9mxtmxyPv)

-Epoch's GPT-5 estimate: 6.5e25 +/- 1.5 OOMs
-GPT-5.2 / GPT-5 API cost ratio: 1.4x
-Naive 'training compute' proportional to 'inference cost ^2', rule gives 2x training compute. 
-This gives 1.3e26 FLOP as central estimate.
-Naively applying the same uncertainty (+/- 1.5 OOMs) gives about 4e25 - 4.2e27. 

Another method is to assume their biggest training used the same % of total compute as the biggest 2024 training run. Epoch estimate GPT-4.5 as 3.8e26 fp8 FLOP. In 2024, they had 200MW at the start of the year and 600MW at the end of the year. With 1.4 kW / H100e, this is 143K to 430K, which has geomean 250K H100e, giving a compute budget of 4.5e27 fp8 FLOP, which implies the GPT 4.5 run was ~8% of their compute budget. 

In 2025, at the start of the year, they had 600MW, with 1.4 kW / H100e, giving 430K H100e, which is 3.2e26 FLOP/month, and 1.28e27 FLOP/month at the end of the year. Geometric mean is 6.4e26 FLOP/month, so 7.7e27 FLOP/year for 2025. 

8% * 7.7e27 = 6e26 FLOP. 

Given this, I think a guess for ""best (incl. not yet released) model at OpenBrain in Dec 2025"" training compute can be closer to this value. Let's say 5% of the compute budget, so 4e26 FLOP. E.g., it seems plausible GPT 5.3 was mostly trained by end of December 2025.",Scenario text,,2026,4E+26,4E+27,3.8E+26
Compute: DeepCent compute budget,Late 2025,1.05,"Our best guess is that the Chinese company with the highest compute budget is ByteDance, at ~2.3e25 FLOP/month, up from an Apr 2025 value of ~7.2e25/month. This happened in Jan 2026 in AI 2027 (based on interpolating between our late 2025 and mid 2026 side panel predictions).","https://eu.36kr.com/en/p/3355663168096262 
https://newsletter.semianalysis.com/p/2025-ai-diffusion-export-controls-microsoft-regulatory-capture-oracle-tears
https://www.techspot.com/news/110432-alibaba-bytedance-moving-ai-training-offshore-bypass-china.html 
https://www.chinatalk.media/p/chinas-weird-chip-surplus-explained 

ByteDance:
- 2024 capex was 80B yuan ($11B), expected to double to 160B yuan ($22B) in 2025. Assuming $50B/1GW of H100e, that would be 90/160*22 / 50 = 440MW of H100e, or 315K of H100e. 
- Third-party estimates put ByteDance's training compute demand at ~267k cards and inference at ~337k cards (based on 400 TFLOPS FP16 reference card). That would be 240K H100e. 

Best guess is ~300K H100e.",Side panel: compute,2026.04,2026,2.25E+26,2.1E+26,7.2E+25
Compute: Global AI datacenter spending,Late 2025,1.19,"Our best guess is that global AI datacenter spending is $423B/year, which happened in Feb 2026 in AI 2027 (based on interpolating between our late 2025 and mid 2026 side panel predictions), up from $308B in Apr 2025.",https://www.ubs.com/global/en/wealthmanagement/insights/chief-investment-office/house-view/daily/2025/latest-04112025.html,Side panel,2026.14,2026,423000000000,400000000000,308000000000
Compute: Global H100e available,Late 2025,1.31,"Our best guess is that as of end of 2025 there were ~22M H100-equivalents available globally, which happened in Mar 2026 in AI 2027 as per our compute forecast (based on interpolating between our EO2025 and EO2026 compute forecast predictions), up from ~10M in Apr 2025.",https://epoch.ai/data-insights/ai-chip-production,"Compute forecast, first table",2026.23,2026,21700000,18000000,9500000
Compute: OpenBrain compute budget,Late 2025,0.84,"Our best guess is that the leading AI company compute budget was at ~1.3e27 FLOP/month as of end of 2025, up from ~6.4e26 in Apr 2025. This was achieved in Nov 2025 in AI 2027 (based on interpolating between our mid 2025 and late 2025 side panel predictions).","From Semianalysis, we have 1.4 kW per H100e in 2024 (assuming all H100s) of IT load, and 1.0 kW per  H100e in 2025 (assuming all GB200s added), which gives (assuming 1:2 weights) 33%*1.4 + 66%*1.0 = 1.12 kW / H100e, resulting in 1.9 GW / 1.12 (kW/H100e) = 1.7M H100e. 
H100e do 2.5e21 raw FLOP/month, at 30% utilization this is about 7.5e20 FLOP/month. 1.7M*7.5e20 = 1.28e27",Side panel: compute,2025.88,2026,1.28E+27,1.5E+27,6.4E+26
Compute: OpenBrain datacenter capacity,Late 2025,0.96,Our best guess is that the leading AI company datacenter capacity at the end of 2025 was at ~1.9 GW. This happened in Dec 2025 in AI 2027 (based on interpolating between our mid 2025 and late 2025 side panel predictions).,"https://openai.com/index/a-business-that-scales-with-the-value-of-intelligence/

OpenAI CFO Sarah Friar disclosed in a blog post that the company grew its data center footprint from 200 MW (2023) to 600 MW (2024) to about 1.9 GW by end of 2025. We're assuming this is citing IT capacity (not including PUE) as seems more conventional in the industry, but its ambiguous. ",Footnote 13,2025.972,2026,1.9,2,
Compute: OpenBrain datacenter capex,Late 2025,0.93,Our best guess is that the leading AI company datacenter capex at the end of 2025 was at ~$90B. This happened in Dec 2025 in AI 2027 (based on interpolating between our mid 2025 and late 2025 side panel predictions).,"From Jensen Huang Aug 2026 earnings call, he said $50-60B/GW, and Citibank in Oct 2025 said $50B/GW. Other sources say $40B/GW blended 2024/2025, and Alpha Matica says H100-era was $34-55B/GW. Central guess is $50B for 2025, $40B for 2024, with 2:1 weight, giving $46.67B/GW for (2025) all-in datacenter capex. So 1.9GW*$46.67B = $88.67B",Footnote 13,2025.95,2026,89000000000,100000000000,
Public salience: % of Americans saying that AI is the most important problem,Late 2025,0.52,"We forecasted a rise from 0.38% to 1%, with the end of 2025 value ending up at 0.63%. Graded by assuming a logistic progression.","https://news.gallup.com/poll/1675/most-important-problem.aspx

For the baseline value, we use a rolling average from Mar 2025 to Jun 2025 given that we couldn't find record of older results. We assume that * is 0.5% even though it's actually <0.5%, because that's what we assumed when we made our original prediction.
Dec 2025 is 1%, but we use a rolling average of the Sep-Dec 2025 to get a larger sample size.",Side panel: importance,,2026,0.0063,0.01,0.0038
,,,,,,,,,,
Aggregations,,,,,,,,,,
,,,,,,,,,,
Category,Mean,Median,Sample size,,,,,,,
Mid 2025 benchmarks,0.51,0.51,2,,,,,,,
Coding time horizon,0.85,0.85,2,,,,,,,
AI software R&D uplift,0.17,0.17,2,,,,,,,
Economic value,0.80,0.80,2,,,,,,,
"Capabilities indicators only
(mean of means / median of medians)",0.58,0.66,,,,,,,,
,,,,,,,,,,
Compute,0.90,0.96,7,,,,,,,
Public salience,0.52,0.52,1,,,,,,,
"All
(mean of means / median of medians)",0.63,0.66,,,,,,,,
,,,,,,,,,,
Capabilities indicators only (individual values; except a single average uplift),0.64,0.66,6,,,,,,,
All (individual values; except a single average uplift),0.75,0.84,14,,,,,,,