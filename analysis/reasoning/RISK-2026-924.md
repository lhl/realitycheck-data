# Reasoning: RISK-2026-924

> **Claim**: OpenAI describes cyber “High capability” safeguards as a layered safety stack, including model training to refuse/de-escalate harmful cyber requests, always-on monitoring (including routing some high-risk traffic to less capable models), actor-level enforcement over time, and a Trusted Access for Cyber (TAC) program to provide advanced capabilities to vetted defenders.
> **Credence**: 0.80 (E4)
> **Domain**: RISK

## Evidence Summary

| Direction | Source | Location | Strength | Summary |
|-----------|--------|----------|----------|---------|
| Supports | [openai-2026-gpt-5-3-codex-system-card](../sources/openai-2026-gpt-5-3-codex-system-card.md) | artifact=pdf; locator=Sec. 5.2.1 (Cyber Safeguards) | 0.9 | System card describes layered cyber safeguards inc... |

## Reasoning Chain

The system card describes a multi-layer cyber safeguard stack (training, monitoring and routing, actor-level enforcement, and Trusted Access for Cyber) and presents it as the basis for sufficiency under OpenAI’s Preparedness Framework. This supports high credence that these controls are part of OpenAI’s intended deployment approach, but the real-world protective effect depends on calibration, false positive/negative rates, and adversarial adaptation.

## Trail History

| Date | Credence | Evidence | Status | Pass |
|------|----------|----------|--------|------|
| 2026-02-07 | 0.80 | E4 | active | 1 |

## Data (portable)

```yaml
claim_id: "RISK-2026-924"
reasoning_trail_id: "REASON-2026-237"
credence_at_time: 0.800000011920929
evidence_level_at_time: "E4"
supporting_evidence: []
contradicting_evidence: []
```
