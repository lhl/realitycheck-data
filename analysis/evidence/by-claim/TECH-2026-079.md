# Evidence: TECH-2026-079

> TranslateGemma is produced by a two-stage process: supervised fine-tuning on a mixture of human-translated and synthetic parallel data, followed by reinforcement learning that uses an ensemble of reward models including MetricX-QE and AutoMQM to optimize translation quality.

| ID | Direction | Source | Location | Strength | Status |
|----|-----------|--------|----------|----------|--------|
| EVLINK-2026-133 | supports | google-2026-translategemma-tech-report | Analysis file: analysis/sources/google-2026-translategemma-tech-report.md (claim tables / Claims to Register YAML); URL: https://arxiv.org/abs/2601.09012 | 0.75 | active |