# Evidence: TECH-2026-094

> In the OpenAI case study (Sep 2025–Jan 2026), cached input tokens are about 95.9% of total input tokens, implying a cached-to-fresh reuse factor of roughly 23×.

| ID | Direction | Source | Location | Strength | Status |
|----|-----------|--------|----------|----------|--------|
| EVLINK-2026-143 | supports | lhl-2026-frontier-llm-token-unit-economics | Analysis file: analysis/sources/lhl-2026-frontier-llm-token-unit-economics.md (claim tables / Claims to Register YAML); URL: https://github.com/lhl/frontier-llm-token-unit-economics | 0.85 | active |