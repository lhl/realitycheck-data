# Evidence: TECH-2026-085

> TranslateGemma training uses supervised fine-tuning on human-translated and synthetic parallel data followed by reinforcement learning using reward models such as MetricX-QE and AutoMQM.

| ID | Direction | Source | Location | Strength | Status |
|----|-----------|--------|----------|----------|--------|
| EVLINK-2026-139 | supports | google-2026-translategemma-blog | Analysis file: analysis/sources/google-2026-translategemma-blog.md (claim tables / Claims to Register YAML); URL: https://blog.google/innovation-and-ai/technology/developers-tools/translategemma/ | 0.65 | active |