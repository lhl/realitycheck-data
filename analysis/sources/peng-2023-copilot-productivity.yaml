sources:
  - id: "peng-2023-copilot-productivity"
    type: "PAPER"
    title: "The Impact of AI on Developer Productivity: Evidence from GitHub Copilot"
    author:
      - "Sida Peng"
      - "Eirini Kalliamvakou"
      - "Peter Cihon"
      - "Mert Demirer"
    year: 2023
    url: "https://arxiv.org/abs/2302.06590v1"
    accessed: "2026-01-21"
    status: "analyzed"
    analysis_file: "analysis/sources/peng-2023-copilot-productivity.md"
    reliability: 0.75
    bias_notes: >-
      Controlled trial reported by authors affiliated with Microsoft Research and GitHub;
      potential pro-productivity framing and conflict-of-interest risk; nevertheless provides
      empirical measurement with reported confidence intervals and design details.
    topics:
      - ai
      - developer productivity
      - software engineering
      - github copilot
      - code assistants
      - randomized controlled trial
    domains:
      - LABOR
      - TECH
    claims_extracted:
      - LABOR-2023-001
      - LABOR-2023-002

claims:
  - id: "LABOR-2023-001"
    text: >-
      In a controlled experiment (May–Jun 2022) with 95 professional developers, the group
      with access to GitHub Copilot completed an HTTP-server implementation task in
      JavaScript 55.8% faster than the control group (95% CI: 21–89%).
    type: "[F]"
    domain: "LABOR"
    evidence_level: "E2"
    credence: 0.90
    source_ids: ["peng-2023-copilot-productivity"]
    operationalization: >-
      Replicate with randomized assignment across multiple programming tasks, languages,
      and environments; compare time-to-completion distributions and quality metrics.
    falsifiers:
      - Re-analysis finds measurement/statistical errors that eliminate the effect.
      - Replications across tasks show materially smaller or null time savings.

  - id: "LABOR-2023-002"
    text: >-
      In the same experiment, Copilot’s measured productivity gains were larger for
      less-experienced developers, older programmers, and those who program more hours per
      day.
    type: "[F]"
    domain: "LABOR"
    evidence_level: "E2"
    credence: 0.70
    source_ids: ["peng-2023-copilot-productivity"]
    operationalization: >-
      Estimate heterogeneous treatment effects with pre-registered subgroup analysis and
      replicate with larger samples to validate subgroup patterns.
    falsifiers:
      - Replications do not find the subgroup patterns or find opposite effects.
      - Re-analysis shows subgroup results are not robust to multiple-testing correction.
